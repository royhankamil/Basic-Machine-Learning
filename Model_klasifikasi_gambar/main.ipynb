{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tujuan\n",
    "\n",
    "    Tahap awal sebelum kita membangun sebuah model machine learning adalah mendefinisikan problem statement yang ingin kita selesaikan. Pada tahap ini kita menentukan apa masalah yang ingin diselesaikan dan bagaimana implementasi dari model jaringan saraf tiruan dapat menyelesaikan masalah tersebut. Setelah kita memahami masalah, kita dapat mengembangkan model jaringan saraf tiruan sebagai sebuah solusi.\n",
    "\n",
    "    Pada latihan kali ini kita akan membuat sebuah model untuk mengklasifikasi gambar sebuah kamar dan memprediksi apakah kamar tersebut rapi atau berantakan. Pada akhir latihan Anda dapat menguji model yang telah dibuat dengan menggunakan gambar kamar Anda sendiri. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tahapan Latihan\n",
    "Tentunya machine learning selalu membutuhkan data. Pada tahap awal kita perlu memahami dataset yang kita miliki terlebih dahulu. Beberapa hal yang perlu diketahui adalah format dari data, jumlah sampel, dan berapa jumlah label. Selain itu, kita juga perlu memastikan apakah dataset tersebut merupakan data kontinu (masalah regresi) atau data diskrit (masalah klasifikasi).\n",
    "\n",
    "Dataset yang kita gunakan memiliki 192 sampel data latih yang terdiri dari 96 sampel gambar ruangan rapi dan 96 sampel gambar ruangan berantakan.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tahapan latihan kali ini adalah:\n",
    "\n",
    "1. Memastikan TensorFlow yang digunakan di Google Colab adalah versi di atas 2.0.\n",
    "2. Mengunduh dataset dan melakukan extract file dengan metode unzip.\n",
    "3. Menampung direktori setiap kelas pada direktori train dan validasi ke dalam variabel.\n",
    "4. Pre-processing data dengan image augmentation.\n",
    "5. Mempersiapkan data latih yang akan dipelajari oleh model.\n",
    "6. Membangun arsitektur model dengan Convolutional Neural Network (CNN).\n",
    "7. Compile dan latih model dengan model.compile dan model.fit hingga mendapatkan akurasi yang diinginkan.\n",
    "8. Menguji model yang telah dibuat dengan menggunakan gambar yang belum dikenali oleh model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Rizal\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2.15.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sekarang mempersiapkan dataset yang akan digunakan. Anda dapat mengunduh dataset tersebut dengan menggunakan perintah berikut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!wget --no-check-certificate \\\n",
    "https://dicoding-academy-assets.sgp1.cdn.digitaloceanspaces.com/184/messy-vs-clean-room.zip \\\n",
    "\\-O /tmp/messy_vs_clean_room.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kode di bawah ini berfungsi untuk mengekstrak data yang sebelumnya kita unduh. Lalu kita mendefinisikan nama direktori untuk data latih dan data validasi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/tmp/messy_vs_clean_room.zip'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\Rekayasa_Perangkat_Lunak\\Artificial_Intellegence\\Basic-Machine-Learning\\Model_klasifikasi_gambar\\main.ipynb Cell 8\u001b[0m line \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Rekayasa_Perangkat_Lunak/Artificial_Intellegence/Basic-Machine-Learning/Model_klasifikasi_gambar/main.ipynb#W6sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mzipfile\u001b[39;00m\u001b[39m,\u001b[39m \u001b[39mos\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Rekayasa_Perangkat_Lunak/Artificial_Intellegence/Basic-Machine-Learning/Model_klasifikasi_gambar/main.ipynb#W6sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m local_zip \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m/tmp/messy_vs_clean_room.zip\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Rekayasa_Perangkat_Lunak/Artificial_Intellegence/Basic-Machine-Learning/Model_klasifikasi_gambar/main.ipynb#W6sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m zip_ref \u001b[39m=\u001b[39m zipfile\u001b[39m.\u001b[39;49mZipFile(local_zip, \u001b[39m'\u001b[39;49m\u001b[39mr\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Rekayasa_Perangkat_Lunak/Artificial_Intellegence/Basic-Machine-Learning/Model_klasifikasi_gambar/main.ipynb#W6sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m zip_ref\u001b[39m.\u001b[39mextractall(\u001b[39m'\u001b[39m\u001b[39m/tmp\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Rekayasa_Perangkat_Lunak/Artificial_Intellegence/Basic-Machine-Learning/Model_klasifikasi_gambar/main.ipynb#W6sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m zip_ref\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\Rizal\\AppData\\Local\\Programs\\Python\\Python39\\lib\\zipfile.py:1239\u001b[0m, in \u001b[0;36mZipFile.__init__\u001b[1;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps)\u001b[0m\n\u001b[0;32m   1237\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m   1238\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1239\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfp \u001b[39m=\u001b[39m io\u001b[39m.\u001b[39;49mopen(file, filemode)\n\u001b[0;32m   1240\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m:\n\u001b[0;32m   1241\u001b[0m         \u001b[39mif\u001b[39;00m filemode \u001b[39min\u001b[39;00m modeDict:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/tmp/messy_vs_clean_room.zip'"
     ]
    }
   ],
   "source": [
    "# melakukan ekstraksi pada file zip\n",
    "import zipfile, os\n",
    "\n",
    "local_zip = '/tmp/messy_vs_clean_room.zip'\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall('/tmp')\n",
    "zip_ref.close()\n",
    "\n",
    "base_dir = '/tmp/images'\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'val')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setelah Anda jalankan kode di atas, perhatikanlah, direktori data latih dan data validasi masing-masing memiliki sub-direktori clean dan messy. Setiap sub-direktori menyimpan gambar yang sesuai dengan nama sub-direktori tersebut. Jadi, pada sub-direktori ‘clean’ terdapat gambar-gambar ruangan yang rapi dan pada sub-direktori ‘messy’ terdapat gambar-gambar ruangan yang berantakan.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['clean', 'messy']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('/tmp/images/train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['clean', 'messy']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('/tmp/images/val')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Langkah selanjutnya, kita akan menerapkan ImageDataGenerator untuk data latih dan data validasi. ImageDataGenerator merupakan sebuah fungsi yang sangat berguna untuk mempersiapkan data latih dan data validasi. Beberapa kemudahan yang disediakan ImageDataGenerator antara lain, preprocessing data, pelabelan sampel otomatis, dan augmentasi gambar.\n",
    "\n",
    "Augmentasi gambar merupakan sebuah teknik yang dapat digunakan untuk memperbanyak data latih dengan cara menduplikasi gambar yang telah ada dengan menambahkan variasi tertentu. Anda akan mempelajari lebih dalam terkait teknik ini pada kelas “Belajar Pengembangan Machine Learning”. Anda juga dapat melihat detail mengenai augmentasi gambar menggunakan ImageDataGenerator pada https://keras.io/preprocessing/image/ . "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kode berikut menunjukkan proses augmentasi gambar pada setiap sampel dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "                rescale=1./255,\n",
    "                rotation_range=20,\n",
    "                horizontal_flip=True,\n",
    "                shear_range=0.2,\n",
    "                fill_mode='nearest'\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "                rescale=1./255\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selanjutnya, siapkan data latih dan validasi dari kumpulan data gambar yang di-load dalam memori melalui fungsi flow() berikut.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 192 images belonging to 2 classes.\n",
      "Found 20 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,  # direktori data latih\n",
    "        target_size=(150, 150),  # mengubah resolusi seluruh gambar menjadi 150x150 piksel\n",
    "        batch_size=4,\n",
    "        # karena ini merupakan masalah klasifikasi 2 kelas, gunakan class_mode = 'binary'\n",
    "        class_mode='binary')\n",
    " \n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_dir, # direktori data validasi\n",
    "        target_size=(150, 150), # mengubah resolusi seluruh gambar menjadi 150x150 piksel\n",
    "        batch_size=4, # karena ini merupakan masalah klasifikasi 2 kelas gunakan class_mode = 'binary'\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setelah data siap, kita bisa membangun model Convolutional Neural Network (CNN). Pembuatan model CNN pada keras mirip dengan pembuatan model Multi Layer Perceptron (MLP) yang dibahas pada modul sebelumnya. Perbedaannya terdapat pada empat lapis layer konvolusi dan max pooling. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " fungsi dari layer konvolusi adalah untuk mengekstraksi atribut pada gambar. Sedangkan layer max pooling berguna untuk mereduksi resolusi gambar sehingga proses pelatihan model lebih cepat. Nah, pada model CNN, proses klasifikasi gambar hanya berfokus pada atribut-atribut unik yang membedakan tiap kategori. Sehingga, teknik ini dinilai lebih optimal dibandingkan hanya menggunakan model MLP yang membedakan tiap kategori dengan melihat keseluruhan piksel-piksel pada gambar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(512, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usai membuat model, kita bisa menggunakan fungsi summary() untuk melihat summary dari arsitektur model yang telah kita buat.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_4 (Conv2D)           (None, 148, 148, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPoolin  (None, 74, 74, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 72, 72, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPoolin  (None, 36, 36, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 34, 34, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPoolin  (None, 17, 17, 128)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 15, 15, 512)       590336    \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPoolin  (None, 7, 7, 512)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 25088)             0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 512)               12845568  \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13529665 (51.61 MB)\n",
      "Trainable params: 13529665 (51.61 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### penjelasan summary\n",
    "Berdasarkan hasil summary di atas, model yang kita buat terdiri dari empat lapis Convolutional dan MaxPoling layer, sebuah flatten layer, serta dua buah dense layer. Ingatlah bahwa dense layer terakhir merupakan output layer. Pada kasus klasifikasi biner, output model merupakan angka tunggal antara 0 dan 1. Sehingga, kita set dense layer terakhir = 1. Sementara itu, kolom “Param #” berisi informasi mengenai jumlah parameter pada tiap layer.\n",
    "\n",
    "Selanjutnya, kolom “Output Shape” berisi informasi ukuran output yang dihasilkan tiap layer. Jika diperhatikan, ukuran input gambar yang telah didefinisikan sebelumnya adalah sebesar (150, 150). Tapi pada convolutional layer pertama, setiap satu input gambar akan menghasilkan ukuran output (148, 148) sebanyak 32 gambar. Ukuran tersebut berkurang karena kita menggunakan filter dengan ukuran (3, 3) dengan jumlah filter sebanyak 32 filter. Sehingga, tiap satu input gambar akan menghasilkan 32 gambar baru dengan ukuran (148, 148). \n",
    "\n",
    "Kemudian, resolusi tiap gambar akan diperkecil dengan tetap mempertahankan informasi pada gambar menggunakan MaxPoling layer yang berukuran (2, 2). Hal ini  akan menghasilkan ukuran output gambar sebesar (74, 74). Nah, proses tersebut juga berlaku untuk Convolutional dan MaxPoling layer yang lain. \n",
    "\n",
    "Berikutnya, mari perhatikan flatten layer. Output dari MaxPoling layer terakhir yang terdiri dari 512 gambar dengan ukuran (7, 7) akan diubah ke dalam bentuk array 1D (tensor 1D). Hal ini  akan menghasilkan output berukuran (25088). \n",
    "\n",
    "Nah, output tersebut kemudian masuk ke dalam dense layer pertama yang memiliki 512 neuron. Sehingga, ia akan menghasilkan output dengan ukuran (512). Selanjutnya, output ini akan masuk pada dense layer kedua yang memiliki 1 neuron sehingga akan menghasilkan output dengan ukuran (1). Output dari layer terakhir inilah yang digunakan sebagai hasil akhir model untuk kasus klasifikasi biner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setelah membuat arsitektur model CNN, tahap selanjutnya adalah melakukan compile model tersebut menggunakan fungsi compile(). Pada tahap ini, kita juga menentukan loss function serta optimizer yang akan digunakan. Loss function yang digunakan pada kasus klasifikasi biner adalah \"binary_crossentropy\". Selain itu, optimizer yang digunakan  pada kasus ini adalah \"Adam optimizer\". Adam optimizer dipilih karena mudah diterapkan, lebih efisien secara komputasi dan kebutuhan memori yang lebih kecil.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer=tf.optimizers.Adam(),\n",
    "    metrics=['accuracy']\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nah, tahap terakhir dari pembuatan model adalah proses yang disebut sebagai model fitting. Ia merupakan proses untuk melatih model pada data masukan dan label yang bersesuaian. Pada proses ini, kita memasukkan data latih pada jaringan Neural Network yang telah kita buat sebelumnya. \n",
    "\n",
    "Hal yang harus didefinisikan pada tahap ini adalah loss function dan optimizer. Kemudian, kita mulai proses pelatihan model dengan memanggil fungsi fit(). \n",
    "\n",
    "Dengan menggunakan ImageDataGenerator, kita tidak perlu memasukkan parameter gambar dan labelnya. Image data generator secara otomatis melabeli gambar sesuai dengan direktorinya. Sebagai contoh,  sebuah gambar yang terdapat di direktori clean, akan diberi label “clean” oleh ImageDataGenerator secara otomatis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "WARNING:tensorflow:From c:\\Users\\Rizal\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\Rizal\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "25/25 - 48s - loss: 0.7611 - accuracy: 0.4800 - val_loss: 0.6779 - val_accuracy: 0.5000 - 48s/epoch - 2s/step\n",
      "Epoch 2/20\n",
      "25/25 - 24s - loss: 0.7009 - accuracy: 0.4200 - val_loss: 0.6793 - val_accuracy: 0.6000 - 24s/epoch - 978ms/step\n",
      "Epoch 3/20\n",
      "25/25 - 21s - loss: 0.6749 - accuracy: 0.6200 - val_loss: 0.6095 - val_accuracy: 0.7000 - 21s/epoch - 856ms/step\n",
      "Epoch 4/20\n",
      "25/25 - 26s - loss: 0.6151 - accuracy: 0.7200 - val_loss: 0.8083 - val_accuracy: 0.5000 - 26s/epoch - 1s/step\n",
      "Epoch 5/20\n",
      "25/25 - 21s - loss: 0.7472 - accuracy: 0.4600 - val_loss: 0.6645 - val_accuracy: 0.5000 - 21s/epoch - 839ms/step\n",
      "Epoch 6/20\n",
      "25/25 - 36s - loss: 0.6518 - accuracy: 0.6200 - val_loss: 0.6135 - val_accuracy: 0.6000 - 36s/epoch - 1s/step\n",
      "Epoch 7/20\n",
      "25/25 - 32s - loss: 0.6299 - accuracy: 0.7100 - val_loss: 0.6218 - val_accuracy: 0.7500 - 32s/epoch - 1s/step\n",
      "Epoch 8/20\n",
      "25/25 - 44s - loss: 0.6144 - accuracy: 0.7400 - val_loss: 0.5172 - val_accuracy: 0.7500 - 44s/epoch - 2s/step\n",
      "Epoch 9/20\n",
      "25/25 - 23s - loss: 0.5587 - accuracy: 0.7100 - val_loss: 0.5324 - val_accuracy: 0.7500 - 23s/epoch - 909ms/step\n",
      "Epoch 10/20\n",
      "25/25 - 53s - loss: 0.5851 - accuracy: 0.7500 - val_loss: 0.4970 - val_accuracy: 0.7500 - 53s/epoch - 2s/step\n",
      "Epoch 11/20\n",
      "25/25 - 30s - loss: 0.7079 - accuracy: 0.5700 - val_loss: 0.6277 - val_accuracy: 0.5500 - 30s/epoch - 1s/step\n",
      "Epoch 12/20\n",
      "25/25 - 24s - loss: 0.6115 - accuracy: 0.7100 - val_loss: 0.5629 - val_accuracy: 0.7500 - 24s/epoch - 947ms/step\n",
      "Epoch 13/20\n",
      "25/25 - 28s - loss: 0.5291 - accuracy: 0.7500 - val_loss: 0.7525 - val_accuracy: 0.6000 - 28s/epoch - 1s/step\n",
      "Epoch 14/20\n",
      "25/25 - 33s - loss: 0.5216 - accuracy: 0.7600 - val_loss: 0.6753 - val_accuracy: 0.6000 - 33s/epoch - 1s/step\n",
      "Epoch 15/20\n",
      "25/25 - 29s - loss: 0.5818 - accuracy: 0.7200 - val_loss: 0.5417 - val_accuracy: 0.7500 - 29s/epoch - 1s/step\n",
      "Epoch 16/20\n",
      "25/25 - 30s - loss: 0.6478 - accuracy: 0.5500 - val_loss: 0.6323 - val_accuracy: 0.8000 - 30s/epoch - 1s/step\n",
      "Epoch 17/20\n",
      "25/25 - 27s - loss: 0.6008 - accuracy: 0.6800 - val_loss: 0.6663 - val_accuracy: 0.5500 - 27s/epoch - 1s/step\n",
      "Epoch 18/20\n",
      "25/25 - 31s - loss: 0.6046 - accuracy: 0.6600 - val_loss: 0.5642 - val_accuracy: 0.7000 - 31s/epoch - 1s/step\n",
      "Epoch 19/20\n",
      "25/25 - 29s - loss: 0.5176 - accuracy: 0.7600 - val_loss: 0.4366 - val_accuracy: 0.8000 - 29s/epoch - 1s/step\n",
      "Epoch 20/20\n",
      "25/25 - 30s - loss: 0.5310 - accuracy: 0.8100 - val_loss: 0.5505 - val_accuracy: 0.6500 - 30s/epoch - 1s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x25fe6d4fa90>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# latih model dengan model.fit\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=25, # beberapa bach yang akan dieksekusi pada setiap epoch\n",
    "    epochs=20, # tambahkan epochs jika akurasi model belum optimal\n",
    "    validation_data=validation_generator, # menampilkan akurasi pengujian data validasi\n",
    "    validation_steps=5, # beberapa batch yang akan dieksekusi pada setiap epoch\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sampai di sini, proses training telah selesai. Anda telah berhasil membuat model machine learning dengan CNN untuk mengklasifikasi gambar ruangan yang bersih dan berantakan. Selamat!\n",
    "\n",
    "Setelah berhasil membuat model, Anda tentu ingin menguji model tersebut untuk memprediksi gambar baru (gambar yang belum dikenal oleh model sebelumnya). Potongan program berikut memungkinkan kita secara interaktif memilih sebuah gambar. Kemudian, gambar tersebut akan diolah terlebih dahulu sebelum dimasukkan ke model untuk diprediksi. \n",
    "\n",
    "Sebelum menerapkan kode ini, pastikan Anda telah memiliki contoh gambar yang akan diuji. Anda dapat mencari dan mengunduh gambar tersebut dari mesin pencari Google. Atau, Anda dapat menggunakan gambar dari https://drive.google.com/drive/folders/1_k9DSTSld-9kcJ_aW3vBLkdm3lWYbaze?usp=sharing berikut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from google.colab import files\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "\n",
    "uploaded = files.upload()\n",
    "\n",
    "for fn in uploaded.keys():\n",
    "    # predicting images \n",
    "    path = fn\n",
    "    img = image.load_img(path, target_size=(150, 150))\n",
    "\n",
    "    imgplot = plt.imshow(img)\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    images = np.vstack([x])\n",
    "\n",
    "    classes = model.predict(images, batch_size=10)\n",
    "    print(fn)\n",
    "    if classes==0:\n",
    "        print('clean')\n",
    "    else:\n",
    "        print('messy')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
